{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfj0lEQVR4nO3deXhcd33v8fd3Rptly3Icybtj2Y7jJYudWHE2AikkxHYAQ1muoSFAQkMo4dL2oZdQ7qULvb2XUnjoEmoMyUOapqRJCcSkTuyEJYEbnNhxvMmrvMuSZXmRLFnraL73jxmbQRlZY3lGZ2b0eT3PPJpzzk+aj4+kj4/OnMXcHRERyX2hoAOIiEh6qNBFRPKECl1EJE+o0EVE8oQKXUQkTxQE9cIVFRVeVVUV1MuLiOSkN95447i7VyZbFlihV1VVsWHDhqBeXkQkJ5nZwf6WaZeLiEieUKGLiOQJFbqISJ5QoYuI5AkVuohInhiw0M3sUTM7Zmbb+lluZvaPZlZrZlvM7Lr0xxQRkYGksoX+A2DxeZYvAWbFH/cD/3LxsURE5EINeBy6u79iZlXnGbIM+FePXYd3nZmNMbOJ7t6Qpowikufcna5INP7opTsSpafX6emN0h2JEok6kd7YvN6oE4lG4x+daNTp9dj8qDu9UYi644nP468RjcaeRz02HXttcDw+L/Y88arivzuOc8/PLccTxibO/51/4O/8e6urxvL2K5KeG3RR0nFi0WTgcMJ0XXzeWwrdzO4nthXPZZddloaXFpGguTutXRGaWrs40dbNyTPdNLd3c6q9h9OdPbR09NDaGeFMV4S2zghnuiO0d/fS3h2ho7uXzkistPOd2W+fP/COmVlb6JZkXtK7Zrj7SmAlQHV1te6sIZIjTrR1sf/4GQ6caOfQiTPUneqgvqWD+uZOjrV20tmTvJALQkb5iELKSgoYVVLAyKICxo8uobQoTGlRmBGFYUoKwxQXhikuCFFSGKaoIERxOERRQYjCcIiCsFEU/xgOGYXhEOGQEbbY9NlH6Oy0GaEQhMziDzAzzPjtNAYWK1kjtvzs/LPFe+5j4rz42LPPz0osa7NklTg00lHodcDUhOkpQH0avq6IDLFo1Nl3vI3Nh1vYeqSFnUdPs6exjRNnus+NCRlMLB/BxPIS5k8dw4TRxYwrK6GyrJixI4vOPcaUFjKiMBxowQ036Sj0VcCDZvYkcAPQov3nIrkhGnVq6k/zm33HWbfvJOv3n6S1KwJAaVGY2RPKuGPeeGaNL2NG5UiqLh3J5DEjKCrQEc/ZaMBCN7MfArcBFWZWB/wFUAjg7iuA1cBSoBZoBz6VqbAicvG6Ir38avdxXtrRyM92HqOptQuAmZUjee+CSVw7dQzzp45hZuUowiFtXeeSVI5y+egAyx34XNoSiUjauTtvHm7mmY11/HRzAy0dPYwqLuAdsyu5fe44brm8gnFlJUHHlIsU2OVzRSTzuiNRfrq5nkd+vZ/tDacpKQxx55UTeP+1k7llZoV2neQZFbpIHuqK9PJv6w7x3Zf3cqy1i1njRvG3H7ia986fSFlJYdDxJENU6CJ5pDfqPLOxjm+/tIcjzR3cNONSvvHh+bx9VoWONhkGVOgieaKmvoUvP7OVLXUtXDOlnK9/8BreNqsi6FgyhFToIjmus6eXb7+0h+/9ah+XlBbyD8sX8L75k7RFPgyp0EVyWO2xNv7oiTfY3djGR6qn8OdL5zKmtCjoWBIQFbpIjlq1uZ4v/2gLxYVhHrt3Ee/IwLVBJLeo0EVyTDTq/O/VO3jk1/upnnYJ//yx65hQrmPIRYUuklO6Ir386VOb+a8tDXzy5iq+ctdcCsM6llxiVOgiOaK1s4fPPP4Gr+49wZ8vncP9b58ZdCTJMip0kRzQ1hXh7kdep+ZIC9/6yHx+/7opQUeSLKRCF8lynT29fPqx9Ww70sKKuxdyx7zxQUeSLKWdbyJZrKc3yoP/vpHX9p/kWx+ZrzKX81Khi2Qpd+dL/7mFl3Yc46+XXcWyBZODjiRZToUukqUe+fV+nnnzCH9y+xV8/MZpQceRHKBCF8lC/6/2OH+7egeLr5zAf3/X5UHHkRyhQhfJModPtvPgv29kZuUo/v4j83VNFkmZCl0ki3RHonz2iTeIRJ2V91QzqlgHoknq9NMikkX+6ed72HbkNCvuXsj0ipFBx5Ecoy10kSyx8dApHv5FLR9aOIXFV00IOo7kIBW6SBbo6O7li09tZmL5CL763nlBx5EcpV0uIlng6y/sZN/xM/z7H97AaN3zUwZJW+giAdt0uJnHfnOAT95cxc0zdcs4GTwVukiAolHnq89uo3JUMV+8c3bQcSTHqdBFAvTUhsNsqWvhK3fN1SGKctFU6CIBaW7v5usv7GRR1VjeN39S0HEkD6jQRQLyzbW7aeno4a+WXamzQSUtVOgiAag91soTrx3k4zdOY+7E0UHHkTyhQhcJwLde3M2IwjBfuP2KoKNIHlGhiwyxbUdaWL31KPfdOoOxI4uCjiN5RIUuMsT+fu0uykcU8ulbpwcdRfJMSoVuZovNbJeZ1ZrZQ0mWl5vZT81ss5nVmNmn0h9VJPetP3CSX+5q4rO3zdQZoZJ2Axa6mYWBh4ElwDzgo2bW92ITnwO2u/t84Dbgm2amvyVFErg731izi8qyYj5xU1XQcSQPpbKFvgiodfd97t4NPAks6zPGgTKLHXs1CjgJRNKaVCTHvbb/JK/vP8nnbpvJiKJw0HEkD6VS6JOBwwnTdfF5if4ZmAvUA1uBL7h7tO8XMrP7zWyDmW1oamoaZGSR3PTdl/dy6cgili+6LOgokqdSKfRkZzx4n+k7gU3AJGAB8M9m9paDa919pbtXu3t1ZWXlBYcVyVU7j57mF7ua+OTNVZQUautcMiOVQq8DpiZMTyG2JZ7oU8AzHlML7AfmpCeiSO5b+fI+SovCfPymaUFHkTyWSqGvB2aZ2fT4G53LgVV9xhwC3gVgZuOB2cC+dAYVyVVHmjtYtbme5ddfxphSHSsgmTPg5d3cPWJmDwJrgDDwqLvXmNkD8eUrgK8BPzCzrcR20XzJ3Y9nMLdIznjkV/tx4D4ddy4ZltL1Ot19NbC6z7wVCc/rgXenN5pI7mtp7+HJ9Yd43/xJTB4zIug4kud0pqhIBj39xmHau3t1VqgMCRW6SIZEo86/rTtI9bRLuHJSedBxZBhQoYtkyK9rj3PgRLuObJEho0IXyZDH1x3k0pFFLL5qQtBRZJhQoYtkwJHmDn62o5H/dv1Uigt0IpEMDRW6SAb88LVDAHzsBp3mL0NHhS6SZt2RKE+uP8Q754xnyiWlQceRYUSFLpJmL25v5HhbN3ffqK1zGVoqdJE0e/qNw0wsL+HWWboAnQwtFbpIGh1t6eSV3U188LophEPJLlQqkjkqdJE0eubNOqIOH1o4JegoMgyp0EXSxN35zw11XF91CVUVI4OOI8OQCl0kTTYeOsW+42f48MKpAw8WyQAVukiaPL2hjhGFYZZeMzHoKDJMqdBF0qC9O8JzWxpYevVERhWndFVqkbRToYukwYvbG2nriujNUAmUCl0kDZ7dVM+k8hJumD426CgyjKnQRS7SyTPdvLK7ifcumERIx55LgFToIhdp9dYGIlFn2fzJQUeRYU6FLnKRVm2qZ9a4UcydWBZ0FBnmVOgiF+FIcwevHzjJsgWTMNPuFgmWCl3kIjy3uR6A986fFHASERW6yEV5dlM9C6aOYdqlOtVfgqdCFxmkPY2tbG84zbIF2jqX7KBCFxmkn25pIGRwl071lyyhQhcZpOe3NrBo+ljGlZUEHUUEUKGLDMqexlb2HGtj6dXaOpfsoUIXGYT/2tqAGSy+akLQUUTOUaGLDMLqrQ1cX6XdLZJdVOgiF6j2WCu7G9u4S7tbJMukVOhmttjMdplZrZk91M+Y28xsk5nVmNnL6Y0pkj1Wbz2q3S2SlQa8Er+ZhYGHgTuAOmC9ma1y9+0JY8YA3wEWu/shMxuXqcAiQVu9tYHqaZcwfrR2t0h2SWULfRFQ6+773L0beBJY1mfMx4Bn3P0QgLsfS29Mkeywt6mNnUdbdXSLZKVUCn0ycDhhui4+L9EVwCVm9ksze8PM7kn2hczsfjPbYGYbmpqaBpdYJEDPb20AYMlVKnTJPqkUerJLyHmf6QJgIXAXcCfwv8zsird8kvtKd6929+rKysoLDisStBdqjnLtZWOYUK7dLZJ9Uin0OmBqwvQUoD7JmBfc/Yy7HwdeAeanJ6JIdqg71c62I6dZfKXeDJXslEqhrwdmmdl0MysClgOr+ox5FrjVzArMrBS4AdiR3qgiwVpT0wjAnSp0yVIDHuXi7hEzexBYA4SBR929xsweiC9f4e47zOwFYAsQBb7v7tsyGVxkqK2pOcqcCWVUVehSuZKdBix0AHdfDazuM29Fn+lvAN9IXzSR7HG8rYv1B07y+XfOCjqKSL90pqhICl7a3og72n8uWU2FLpKCF2qOMnXsCN0IWrKaCl1kAKc7e3i19gSLr5ygG0FLVlOhiwzgFzuP0d0b1bVbJOup0EUGsHZ7IxWjirl26iVBRxE5LxW6yHl0RXr55c5j3DFvPKGQdrdIdlOhi5zHq3tPcKa7l3dfOT7oKCIDUqGLnMfamkZGFoW5eealQUcRGZAKXaQf0ajz4vZGbpszjuKCcNBxRAakQhfpx5uHmzne1sW752l3i+QGFbpIP9ZuP0ph2Pi9OboBl+QGFbpIP17c3siNMy5ldElh0FFEUqJCF0mi9lgb+5rO8G5du0VyiApdJIm1248CcMdc7T+X3KFCF0libU0j10wp163mJKeo0EX6aDzdyabDzbozkeQcFbpIHy9uj91qTocrSq5RoYv0sXZ7I9MrRnL5uFFBRxG5ICp0kQSnO3v4zd7jvHveeF37XHKOCl0kwcu7mujpdV2MS3KSCl0kQeza50Us0LXPJQep0EXiuiK9/GLnMW6fO56wrn0uOUiFLhK3bt9J2roi2t0iOUuFLhK3tuYopUVhbp5ZEXQUkUFRoYsQu/b52u2N3Da7kpJCXftccpMKXQR48/Apmlq7dHao5DQVugjwwjZd+1xynwpdhj13Z01NI7dcXqFrn0tOU6HLsLejoZVDJ9u1u0Vyngpdhr01NUcxg9t17XPJcSp0GfbW1Bzl+mljqSwrDjqKyEVJqdDNbLGZ7TKzWjN76DzjrjezXjP7UPoiimTOgeNn2Hm0VScTSV4YsNDNLAw8DCwB5gEfNbN5/Yz7OrAm3SFFMmVNTexWc9p/LvkglS30RUCtu+9z927gSWBZknGfB34EHEtjPpGMeqHmKFdOGs3UsaVBRxG5aKkU+mTgcMJ0XXzeOWY2GfgAsOJ8X8jM7jezDWa2oamp6UKziqRVfXMHbx5qZunVE4OOIpIWqRR6ssvOeZ/pbwNfcvfe830hd1/p7tXuXl1ZWZlqRpGMWL21AYAlV2l3i+SHghTG1AFTE6anAPV9xlQDT8bv8FIBLDWziLv/JC0pRTLg+W1HmTOhjBmVutWc5IdUttDXA7PMbLqZFQHLgVWJA9x9urtXuXsV8J/AH6nMJZs1tHTwxsFT3KXdLZJHBtxCd/eImT1I7OiVMPCou9eY2QPx5efdby6SjZ7fGju6Zek1KnTJH6nscsHdVwOr+8xLWuTu/smLjyWSWc9va2DOhDJmaneL5BGdKSrDTuPpTjYcPMWSq7R1LvlFhS7DzvNbG3CHu67R0S2SX1ToMuys3nqUK8aP4vJxZUFHEUkrFboMK/XNHaw/eJK7rp4UdBSRtFOhy7Dy3JZ63GHZAhW65B8Vugwrz26qZ/7UMVRVjAw6ikjaqdBl2Kg91kZN/WmWzdfWueQnFboMG6s21xMyeI9OJpI8pUKXYcHdWbXpCDfPrGDc6JKg44hkhApdhoUtdS0cONHO+7S7RfKYCl2GhWc31VMUDnGnLpUreUyFLnkv0hvlp1vquW12JeUjCoOOI5IxKnTJe6/saaKptYsPLpwSdBSRjFKhS957ekMdl44s4p1zxgUdRSSjVOiS106e6ealHY28/9rJFIb14y75TT/hktee3XSEnl7nw9Xa3SL5T4Uuee3pDXVcPbmcORNGBx1FJONU6JK3aupb2N5wmg/pzVAZJlTokree3lBHUTikKyvKsKFCl7zU2dPLs5uOcMe88YwpLQo6jsiQUKFLXnp+WwOn2ntYvmhq0FFEhowKXfLS4785yIyKkdwysyLoKCJDRoUueWfbkRY2HmrmD26cRihkQccRGTIqdMk7T7x2kJLCEB+6Tke3yPCiQpe80tLRw0/erOf9CyZTXqoLccnwokKXvPKjN+ro6Onl7hunBR1FZMip0CVvRKPOv712kGsvG8NVk8uDjiMy5FTokjd+ufsY+5rOcM9N2jqX4UmFLnljxcv7mFRewnuu0ZmhMjyp0CUvbDx0itf3n+S+W2foMrkybKX0k29mi81sl5nVmtlDSZb/gZltiT9eNbP56Y8q0r/vvryX8hGFLL9eZ4bK8DVgoZtZGHgYWALMAz5qZvP6DNsPvMPdrwG+BqxMd1CR/uxtamPt9kbuuWkaI4sLgo4jEphUttAXAbXuvs/du4EngWWJA9z9VXc/FZ9cB+iMDhky33tlH0XhEJ+4uSroKCKBSqXQJwOHE6br4vP6cx/wfLIFZna/mW0wsw1NTU2ppxTpx9GWTp7ZeIQPV0+hYlRx0HFEApVKoSe7GIYnHWj2e8QK/UvJlrv7SnevdvfqysrK1FOK9OOffr4Hx/nM22cGHUUkcKnscKwDEt9pmgLU9x1kZtcA3weWuPuJ9MQT6d+hE+38x/rDLF80laljS4OOIxK4VLbQ1wOzzGy6mRUBy4FViQPM7DLgGeDj7r47/TFF3urbP9tNOGR8/p2zgo4ikhUG3EJ394iZPQisAcLAo+5eY2YPxJevAL4KXAp8x8wAIu5enbnYMtztaWzlx28e4Q9vncH40SVBxxHJCikd4+Xuq4HVfeatSHj+aeDT6Y0m0r9vvbibkUUFPPAO7TsXOUun1EnOefPQKZ7fdpT73jadsSN1v1CRs1ToklN6o85frKphXFkxn751etBxRLKKCl1yylMbDrOlroU/XzqXshLdwEIkkQpdckZzezd/98JOFlWNZdkCXVFRpC8VuuSMv1+7i9OdEf5q2ZXEj6YSkQQqdMkJmw8388Rrh/j4jdOYO3F00HFEspIKXbJeZ08vf/rUJsaXlfAnd1wRdByRrKVrjUrW+8aaXextOsPj9y2ifITeCBXpj7bQJau9uvc4j/x6P/fcNI1bZ+mCbiLno0KXrNXa2cOfPb2FqktLeWjJnKDjiGQ97XKRrBSNOl98ejNHT3fy1GduorRIP6oiA9EWumSl7/yyljU1jXx5yRwWTrsk6DgiOUGFLlnn5zsb+eaLu3n/gknc9zad3i+SKhW6ZJW9TW184clNzJ0wmv/z+9foBCKRC6BCl6xR39zBPY+8TlE4xHc/vpARReGgI4nkFBW6ZIXjbV3c/chrnO7o4bF7F+mWciKDoEMHJHAtHT3c88jr1Dd38Ph9N3DV5PKgI4nkJG2hS6COtXby0ZXr2HOslRV3L+T6qrFBRxLJWdpCl8DsP36Gex59jeOt3Xzvnmpumz0u6EgiOU2FLoHYdLiZ+36wHgd+eP+NLJg6JuhIIjlPhS5Dyt15fN1B/ua5HYwbXcy/3ruIGZWjgo4lkhdU6DJk2roiPPSjLTy3pYF3zhnHtz4ynzGlusmzSLqo0GVI/GLXMf7nj7dx9HQnDy2Zw/23ziAU0klDIumkQpeMOt7WxV//dDurNtdz+bhRPPWZG1k4TUeyiGSCCl0yoq0rwiO/2s/3frWPrkgvf3z7LD5720yKC3T2p0imqNAlrVo7e3jy9cOseHkvJ850s/jKCXzxztlcPk5vfIpkmgpd0uLgiTM89upBntpwmLauCDfPvJT/sXiODkcUGUIqdBm00509rN7SwDMbj/D6gZMUhIz3XDOR+942g6un6PR9kaGmQpcLcvhkOz/feYyXdjSybt8JenqdGZUj+bM7Z/PB66Ywobwk6Igiw5YKXfrVG3X2NbWx6XAzr+0/ybp9J6g71QHAjMqR3HvLdJZcPZH5U8p13XKRLKBCF9ydprYuDhxvZ3djK7sbW9l5tJWaIy2c6e4FYExpITdMH8u9t0znHbMrmamzO0WyTkqFbmaLgX8AwsD33f3/9llu8eVLgXbgk+6+Mc1ZZRB6eqM0t/dw4kwXTa2xR+PpLhpaOqhv7uRIcwcHT5yhPV7cAKOKC5g1fhQfXDiFqyeXM3/qGC6vHKUTgUSy3ICFbmZh4GHgDqAOWG9mq9x9e8KwJcCs+OMG4F/iHyVBNOr0utMbjT/cifQ6kWg09rHX6Yk/7+mN0hWJ0h2J0t0b+9jZ0xt7RKJ0dvfS3t1LR08v7d0R2jojtHXFHi0dPZzu7KG5vYfWzkjSLKNLCpg0ZgSTxozgxhljmTa2lGkVI7lifBmTyku0C0UkB6Wyhb4IqHX3fQBm9iSwDEgs9GXAv7q7A+vMbIyZTXT3hnQHfnl3E1977rcvHXvJt/J+Js4+dfffGXP2y5yd654wLz7WPbY8em7Z2eex5dGo4w5Rj82PfYyVdzR5zItWVBCitCjMqOKCc48Jo0u4YnwZ5SMKuaS0iLGjihhbWkRlWfG5x6hi7W0TyTep/FZPBg4nTNfx1q3vZGMmA79T6GZ2P3A/wGWXXXahWYHY7oDZ48t+d2Y/G5OJsxO3OO3cvORjLGGgYefGWXw6FIotNINQwpiQGSGLPQ+HfjsvbEbIIBSKPw8Z4ZBREH+EwyEKQ0ZBOERh2CgMh+IPo6ggRHFBiKJwmOLCECUFYUoKQ5QUhSktDFMQ1j1KRCQmlUJPVpd9tzdTGYO7rwRWAlRXVw9qm3XhtEtYOO2SwXyqiEheS2Xzrg6YmjA9BagfxBgREcmgVAp9PTDLzKabWRGwHFjVZ8wq4B6LuRFoycT+cxER6d+Au1zcPWJmDwJriB22+Ki715jZA/HlK4DVxA5ZrCV22OKnMhdZRESSSelQB3dfTay0E+etSHjuwOfSG01ERC6EDpEQEckTKnQRkTyhQhcRyRMqdBGRPGH9nTqf8Rc2awIODvLTK4DjaYyTTtmaLVtzQfZmy9ZckL3ZlOvCXWi2ae5emWxBYIV+Mcxsg7tXB50jmWzNlq25IHuzZWsuyN5synXh0plNu1xERPKECl1EJE/kaqGvDDrAeWRrtmzNBdmbLVtzQfZmU64Ll7ZsObkPXURE3ipXt9BFRKQPFbqISJ7I2kI3sw+bWY2ZRc2sus+yL5tZrZntMrM7+/n8sWb2opntiX/MyF0xzOw/zGxT/HHAzDb1M+6AmW2Nj9uQiSx9Xu8vzexIQral/YxbHF+PtWb2UKZzxV/zG2a208y2mNmPzWxMP+OGZJ0NtA7il4X+x/jyLWZ2XaayJLzmVDP7hZntiP8efCHJmNvMrCXhe/zVTOdKeO3zfm8CWmezE9bFJjM7bWZ/3GfMkK0zM3vUzI6Z2baEeSn10qB/L909Kx/AXGA28EugOmH+PGAzUAxMB/YC4SSf/3fAQ/HnDwFfH4LM3wS+2s+yA0DFEK6/vwS+OMCYcHz9zQCK4ut13hBkezdQEH/+9f6+N0OxzlJZB8QuDf08sTtz3Qi8NgTraCJwXfx5GbA7Sa7bgOeG6mfqQr43QayzJN/Xo8ROwglknQFvB64DtiXMG7CXLub3Mmu30N19h7vvSrJoGfCku3e5+35i12Bf1M+4x+LPHwPen5mkMRa7IelHgB9m8nXS7NwNwN29Gzh7A/CMcve17h6JT64jdoeroKSyDs7dBN3d1wFjzGxiJkO5e4O7b4w/bwV2ELtPb64Y8nXWx7uAve4+2LPRL5q7vwKc7DM7lV4a9O9l1hb6efR3Q+q+xnv8rknxj+MynOtWoNHd9/Sz3IG1ZvZG/GbZQ+HB+J+7j/bzp12q6zKT7iW2JZfMUKyzVNZBoOvJzKqAa4HXkiy+ycw2m9nzZnblUGVi4O9N0D9by+l/4yqodQap9dKg111KN7jIFDN7CZiQZNFX3P3Z/j4tybyMHnuZYs6Pcv6t81vcvd7MxgEvmtnO+P/gGckF/AvwNWLr5mvEdgfd2/dLJPnctKzLVNaZmX0FiABP9PNl0r7OkkVNMm9QN0HPBDMbBfwI+GN3P91n8UZiuxTa4u+R/ASYNRS5GPh7E+Q6KwLeB3w5yeIg11mqBr3uAi10d799EJ+W6g2pG81sors3xP/UOzaYjDBwTjMrAH4fWHier1Ef/3jMzH5M7M+qiyqnVNefmX0PeC7Joozd3DuFdfYJ4D3Auzy+4zDJ10j7Oksia2+CbmaFxMr8CXd/pu/yxIJ399Vm9h0zq3D3jF+EKoXvTZA3jl8CbHT3xr4Lglxncan00qDXXS7uclkFLDezYjObTux/19f7GfeJ+PNPAP1t8afD7cBOd69LttDMRppZ2dnnxN4U3JZsbLr02V/5gX5eL5UbgGci22LgS8D73L29nzFDtc6y8ibo8fdkHgF2uPu3+hkzIT4OM1tE7Pf5RCZzxV8rle9NkDeO7/ev5aDWWYJUemnwv5dD8W7vIN8h/gCx/6m6gEZgTcKyrxB7F3gXsCRh/veJHxEDXAr8DNgT/zg2g1l/ADzQZ94kYHX8+Qxi71RvBmqI7XbI9Pp7HNgKbIn/MEzsmys+vZTYERR7hyJX/DVrie0j3BR/rAhynSVbB8ADZ7+nxP4Efji+fCsJR11lMNPbiP2ZvSVhPS3tk+vB+LrZTOzN5ZuH6PuX9HsT9DqLv24psYIuT5gXyDoj9p9KA9AT77L7+uuldP1e6tR/EZE8kYu7XEREJAkVuohInlChi4jkCRW6iEieUKGLiOQJFbqISJ5QoYuI5In/D+VsJ/RqL5GOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperbolic Tangent(tanh)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    a = []\n",
    "    for item in x:\n",
    "        a.append(1/(1+math.exp(-item)))\n",
    "    return a\n",
    "\n",
    "def f2(x):\n",
    "    a = []\n",
    "    for item in x:\n",
    "        a.append(math.tanh(item))\n",
    "    return a\n",
    "\n",
    "x = np.arange(-10., 10., 0.2)\n",
    "y1 = sigmoid(x)\n",
    "y2 = f2(x)\n",
    "\n",
    "print(\"Sigmoid\")\n",
    "plt.plot(x,y1)\n",
    "plt.show()\n",
    "\n",
    "print(\"Hyperbolic Tangent(tanh)\")\n",
    "plt.plot(x,y2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n",
      "Build model...\n",
      "Train...\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.3333\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.3333\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 979us/step - loss: 0.6711 - accuracy: 0.3333\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.3333\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 893us/step - loss: 0.6267 - accuracy: 0.3333\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.3333\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.1667\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 897us/step - loss: 0.6193 - accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6126 - accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5915 - accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.6667\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.3333\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 880us/step - loss: 0.4739 - accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5127 - accuracy: 0.33 - 0s 1ms/step - loss: 0.5127 - accuracy: 0.3333\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4959 - accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.3333\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.3333\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.6667\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.6667\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.6667\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.6667\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3824 - accuracy: 0.6667\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 836us/step - loss: 0.3518 - accuracy: 0.6667\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.6667\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3434 - accuracy: 0.6667\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.6667\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.6667\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 913us/step - loss: 0.3795 - accuracy: 0.6667\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.6667\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.6667\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.6667\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 909us/step - loss: 0.3708 - accuracy: 0.6667\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2549 - accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.6667\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.6667\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.6667\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.6667\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3208 - accuracy: 0.6667\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.2723 - accuracy: 0.6667\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 881us/step - loss: 0.3131 - accuracy: 0.6667\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2806 - accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.6667\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.6667\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4154 - accuracy: 0.6667\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 948us/step - loss: 0.2833 - accuracy: 0.6667\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.6667\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2969 - accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2695 - accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.6667\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2625 - accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 935us/step - loss: 0.3727 - accuracy: 0.5000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.6667\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.6667\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.3333\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3310 - accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.6667\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.6667\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.3333\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.6667\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.6667\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.5000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2695 - accuracy: 0.6667\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.5000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2492 - accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2142 - accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2006 - accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.5000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3698 - accuracy: 0.5000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2003 - accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.5000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.5000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2259 - accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.6667\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2969 - accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1771 - accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.6667\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2314 - accuracy: 0.6667\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.6667\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.5000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3057 - accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.6667\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.5000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4224 - accuracy: 0.5000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1991 - accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2575 - accuracy: 0.6667\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3155 - accuracy: 0.5000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.6667\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.8333\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2658 - accuracy: 0.6667\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.6667\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1978 - accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.6667\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2723 - accuracy: 0.6667\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.5000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.6667\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 882us/step - loss: 0.2776 - accuracy: 0.6667\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2573 - accuracy: 0.6667\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3174 - accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 916us/step - loss: 0.2425 - accuracy: 0.6667\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.6667\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3109 - accuracy: 0.6667\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.6667\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.6667\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.6667\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.5000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 863us/step - loss: 0.2083 - accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 953us/step - loss: 0.1426 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.6667\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.8333\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.6667\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 974us/step - loss: 0.2106 - accuracy: 0.8333\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.6667\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.8333\n",
      "Predicted classes: {} [1 2 3 2 3 1]\n",
      "Expected classes: {} [1 2 3 2 3 1]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import numpy as np\n",
    "\n",
    "max_features = 4 # 0,1,2,3 (total of 4)\n",
    "x = [\n",
    "    [[0],[1],[1],[0],[0],[0]],\n",
    "    [[0],[0],[0],[2],[2],[0]],\n",
    "    [[0],[0],[0],[0],[3],[3]],\n",
    "    [[0],[2],[2],[0],[0],[0]],\n",
    "    [[0],[0],[3],[3],[0],[0]],\n",
    "    [[0],[0],[0],[0],[1],[1]]\n",
    "]\n",
    "x = np.array(x,dtype=np.float32)\n",
    "y = np.array([1,2,3,2,3,1],dtype=np.int32)\n",
    "\n",
    "# Convert y2 to dummy variables\n",
    "y2 = np.zeros((y.shape[0], max_features),dtype=np.float32)\n",
    "y2[np.arange(y.shape[0]), y] = 1.0\n",
    "print(y2)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, input_shape=(None, 1)))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print('Train...')\n",
    "model.fit(x,y2,epochs=200)\n",
    "pred = model.predict(x)\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "print(\"Predicted classes: {}\",predict_classes)\n",
    "print(\"Expected classes: {}\",predict_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting file:\n",
      "   year  month  day  dec_year  sn_value  sn_error  obs_num\n",
      "0  1818      1    1  1818.001        -1       NaN        0\n",
      "1  1818      1    2  1818.004        -1       NaN        0\n",
      "2  1818      1    3  1818.007        -1       NaN        0\n",
      "3  1818      1    4  1818.010        -1       NaN        0\n",
      "4  1818      1    5  1818.012        -1       NaN        0\n",
      "5  1818      1    6  1818.015        -1       NaN        0\n",
      "6  1818      1    7  1818.018        -1       NaN        0\n",
      "7  1818      1    8  1818.021        65      10.2        1\n",
      "8  1818      1    9  1818.023        -1       NaN        0\n",
      "9  1818      1   10  1818.026        -1       NaN        0\n",
      "Ending file:\n",
      "       year  month  day  dec_year  sn_value  sn_error  obs_num\n",
      "74013  2020      8   22  2020.641         0       0.0       47\n",
      "74014  2020      8   23  2020.643         0       0.0       42\n",
      "74015  2020      8   24  2020.646         0       0.0       46\n",
      "74016  2020      8   25  2020.649         0       0.0       37\n",
      "74017  2020      8   26  2020.652         0       0.0       34\n",
      "74018  2020      8   27  2020.654         0       0.0       35\n",
      "74019  2020      8   28  2020.657         0       0.0       35\n",
      "74020  2020      8   29  2020.660         0       0.0       31\n",
      "74021  2020      8   30  2020.663         0       0.0       30\n",
      "74022  2020      8   31  2020.665         0       0.0       36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names = ['year', 'month', 'day', 'dec_year', 'sn_value' , \n",
    "         'sn_error', 'obs_num']\n",
    "\n",
    "df = pd.read_csv('sunspot.csv',sep=';',header=None,names=names,na_values=['-1'],index_col=False)\n",
    "\n",
    "print(\"Starting file:\")\n",
    "print(df[0:10])\n",
    "\n",
    "print(\"Ending file:\")\n",
    "print(df[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n"
     ]
    }
   ],
   "source": [
    "start_id = max(df[df['obs_num'] == 0].index.tolist())+1  # Find the last zero and move one beyond\n",
    "print(start_id)\n",
    "df = df[start_id:] # Trim the rows that have missing observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 55160 observations.\n",
      "Test set has 7549 observations.\n"
     ]
    }
   ],
   "source": [
    "df['sn_value'] = df['sn_value'].astype(float)\n",
    "df_train = df[df['year']<2000]\n",
    "df_test = df[df['year']>=2000]\n",
    "\n",
    "spots_train = df_train['sn_value'].tolist()\n",
    "spots_test = df_test['sn_value'].tolist()\n",
    "\n",
    "print(\"Training set has {} observations.\".format(len(spots_train)))\n",
    "print(\"Test set has {} observations.\".format(len(spots_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (55150, 10, 1)\n",
      "Shape of test set: (7539, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_sequences(seq_size, obs):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(obs)-SEQUENCE_SIZE):\n",
    "        #print(i)\n",
    "        window = obs[i:(i+SEQUENCE_SIZE)]\n",
    "        after_window = obs[i+SEQUENCE_SIZE]\n",
    "        window = [[x] for x in window]\n",
    "        #print(\"{} - {}\".format(window,after_window))\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "        \n",
    "    return np.array(x),np.array(y)\n",
    "    \n",
    "    \n",
    "SEQUENCE_SIZE = 10\n",
    "x_train,y_train = to_sequences(SEQUENCE_SIZE,spots_train)\n",
    "x_test,y_test = to_sequences(SEQUENCE_SIZE,spots_test)\n",
    "\n",
    "print(\"Shape of training set: {}\".format(x_train.shape))\n",
    "print(\"Shape of test set: {}\".format(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[353.],\n",
       "        [240.],\n",
       "        [275.],\n",
       "        ...,\n",
       "        [340.],\n",
       "        [238.],\n",
       "        [287.]],\n",
       "\n",
       "       [[240.],\n",
       "        [275.],\n",
       "        [352.],\n",
       "        ...,\n",
       "        [238.],\n",
       "        [287.],\n",
       "        [294.]],\n",
       "\n",
       "       [[275.],\n",
       "        [352.],\n",
       "        [268.],\n",
       "        ...,\n",
       "        [287.],\n",
       "        [294.],\n",
       "        [342.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[138.],\n",
       "        [141.],\n",
       "        [128.],\n",
       "        ...,\n",
       "        [116.],\n",
       "        [ 95.],\n",
       "        [ 85.]],\n",
       "\n",
       "       [[141.],\n",
       "        [128.],\n",
       "        [130.],\n",
       "        ...,\n",
       "        [ 95.],\n",
       "        [ 85.],\n",
       "        [103.]],\n",
       "\n",
       "       [[128.],\n",
       "        [130.],\n",
       "        [123.],\n",
       "        ...,\n",
       "        [ 85.],\n",
       "        [103.],\n",
       "        [ 66.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Epoch 1/1000\n",
      "1724/1724 - 12s - loss: 1370.7405 - val_loss: 185.5287\n",
      "Epoch 2/1000\n",
      "1724/1724 - 11s - loss: 512.3945 - val_loss: 190.7712\n",
      "Epoch 3/1000\n",
      "1724/1724 - 14s - loss: 505.1109 - val_loss: 189.3777\n",
      "Epoch 4/1000\n",
      "1724/1724 - 15s - loss: 506.5404 - val_loss: 192.4722\n",
      "Epoch 5/1000\n",
      "1724/1724 - 11s - loss: 503.5066 - val_loss: 203.4298\n",
      "Epoch 6/1000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1724/1724 - 10s - loss: 496.7450 - val_loss: 188.1809\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7f50576970>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, dropout=0.0, recurrent_dropout=0.0,input_shape=(None, 1)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, \n",
    "                        verbose=2, mode='auto', restore_best_weights=True)\n",
    "print('Train...')\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "          callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (RMSE): 13.620890149386108\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
